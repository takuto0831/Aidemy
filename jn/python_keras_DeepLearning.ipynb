{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python と Keras による DeepLearning\n",
    "\n",
    "## 学習したいことリスト\n",
    "\n",
    "- NN\n",
    "- CNN\n",
    "- RNN\n",
    "- LSTM\n",
    "\n",
    "## 頻出ワード\n",
    "\n",
    "- batch_size\n",
    "- timesteps\n",
    "- input_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コンピュータビジョンのためのディープラーニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 畳み込みニューラルネットワーク (CNN)\n",
    "\n",
    "* input: (height, width, channels)\n",
    "    - チャネル数: 深さ軸 (RGBの場合3, グレースケールの場合1)\n",
    "    \n",
    "* technic:\n",
    "    - Conv2D(畳み込み演算): パディング, ストライド\n",
    "    - MaxPooling2D(最大値プーリング演算): ダウンサンプリング, 過学習を防ぐ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テキストとシーケンスのためのディープラーニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## リカレントニューラルネットワーク\n",
    "\n",
    "* input: (batch_size, timesteps, input_features)\n",
    "\n",
    "* technic: \n",
    "    - sequence.pad_sequences: 文章のラベルエンコーディングベクトルに対して, ??埋めして同じ長さにする. (パディング) max_lenを超える文章に対しては, 切り詰める.\n",
    "\n",
    "\n",
    "### 出力例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0707 15:57:10.111344 4626269632 deprecation_wrapper.py:119] From /Users/takuto/python-env/py37env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0707 15:57:10.134331 4626269632 deprecation_wrapper.py:119] From /Users/takuto/python-env/py37env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0707 15:57:10.137355 4626269632 deprecation_wrapper.py:119] From /Users/takuto/python-env/py37env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 322,080\n",
      "Trainable params: 322,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, None, 32)          2080      \n",
      "=================================================================\n",
      "Total params: 322,080\n",
      "Trainable params: 322,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "simple_rnn_4 (SimpleRNN)     (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, None, 32)          2080      \n",
      "_________________________________________________________________\n",
      "simple_rnn_6 (SimpleRNN)     (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 328,320\n",
      "Trainable params: 328,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# 最終結果のみ\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.summary()\n",
    "\n",
    "# 全結果\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.summary()\n",
    "\n",
    "# RNN の反復\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# setting \n",
    "max_features =10000\n",
    "max_len = 500\n",
    "batch_size=32\n",
    "\n",
    "# input data\n",
    "(train_set, train_y), (test_set, test_y) = imdb.load_data(num_words = max_features)\n",
    "print('train_set shape: ', train_set.shape, 'test_set shape:', test_set.shape)\n",
    "print('train_y shape: ', train_y.shape, 'test_y shape:', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0埋めして, 配列を同じ長さにする (パディング etc..)\n",
    "train_set = sequence.pad_sequences(train_set, maxlen = max_len)\n",
    "test_set = sequence.pad_sequences(test_set, maxlen = max_len)\n",
    "print('train_set shape: ', train_set.shape, 'test_set shape:', test_set.shape)\n",
    "print('train_y shape: ', train_y.shape, 'test_y shape:', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 322,113\n",
      "Trainable params: 322,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0707 16:19:39.770501 4690511296 deprecation_wrapper.py:119] From /Users/takuto/python-env/py37env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0707 16:19:39.777145 4690511296 deprecation.py:323] From /Users/takuto/python-env/py37env/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0707 16:19:40.235876 4690511296 deprecation_wrapper.py:119] From /Users/takuto/python-env/py37env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.5688 - acc: 0.6961 - val_loss: 0.4376 - val_acc: 0.8028\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.3535 - acc: 0.8547 - val_loss: 0.3659 - val_acc: 0.8470\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.2702 - acc: 0.8947 - val_loss: 0.3748 - val_acc: 0.8498\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 20s 997us/step - loss: 0.2227 - acc: 0.9168 - val_loss: 0.3455 - val_acc: 0.8590\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.1934 - acc: 0.9304 - val_loss: 0.4071 - val_acc: 0.8376\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.1457 - acc: 0.9479 - val_loss: 0.3957 - val_acc: 0.8552\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.1060 - acc: 0.9636 - val_loss: 0.4532 - val_acc: 0.8196\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.0755 - acc: 0.9762 - val_loss: 0.4479 - val_acc: 0.8534\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.0534 - acc: 0.9836 - val_loss: 0.5488 - val_acc: 0.7944\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.0344 - acc: 0.9899 - val_loss: 0.5609 - val_acc: 0.8286\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])\n",
    "history= model.fit(train_set, train_y, epochs=10, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM層とGRU層\n",
    "\n",
    "RNNは長期間の依存関係を学習することは難しい (勾配消失問題). そのためLSTM (Long Short-Term Memory), GRU (Gated Recurrent Unit) が必要. GRUはLSTMと同じ原理に基づいているが, 少し効率化されているため, LSTMほど計算コストがかからない (ただしLSTMほど表現力がない場合がある)\n",
    "\n",
    "* technic\n",
    "    - リカレントドロップアウト\n",
    "    - レカレント層のスタッキング\n",
    "    - 双方向のリカレント層\n",
    "    - 1次元CNNを前処理に利用する\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set shape:  (25000,) test_set shape: (25000,)\n",
      "train_y shape:  (25000,) test_y shape: (25000,)\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# setting \n",
    "max_features =10000\n",
    "max_len = 500\n",
    "batch_size=32\n",
    "\n",
    "# input data\n",
    "(train_set, train_y), (test_set, test_y) = imdb.load_data(num_words = max_features)\n",
    "print('train_set shape: ', train_set.shape, 'test_set shape:', test_set.shape)\n",
    "print('train_y shape: ', train_y.shape, 'test_y shape:', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set shape:  (25000, 500) test_set shape: (25000, 500)\n",
      "train_y shape:  (25000,) test_y shape: (25000,)\n"
     ]
    }
   ],
   "source": [
    "# 0埋めして, 配列を同じ長さにする (パディング etc..)\n",
    "train_set = sequence.pad_sequences(train_set, maxlen = max_len)\n",
    "test_set = sequence.pad_sequences(test_set, maxlen = max_len)\n",
    "print('train_set shape: ', train_set.shape, 'test_set shape:', test_set.shape)\n",
    "print('train_y shape: ', train_y.shape, 'test_y shape:', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0707 17:04:34.850205 4522460608 deprecation_wrapper.py:119] From /Users/takuto/python-env/py37env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0707 17:04:34.855191 4522460608 deprecation_wrapper.py:119] From /Users/takuto/python-env/py37env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 328,353\n",
      "Trainable params: 328,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Embedding, SimpleRNN, Dense, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0707 16:19:39.770501 4690511296 deprecation_wrapper.py:119] From /Users/takuto/python-env/py37env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0707 16:19:39.777145 4690511296 deprecation.py:323] From /Users/takuto/python-env/py37env/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0707 16:19:40.235876 4690511296 deprecation_wrapper.py:119] From /Users/takuto/python-env/py37env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.5688 - acc: 0.6961 - val_loss: 0.4376 - val_acc: 0.8028\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.3535 - acc: 0.8547 - val_loss: 0.3659 - val_acc: 0.8470\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.2702 - acc: 0.8947 - val_loss: 0.3748 - val_acc: 0.8498\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 20s 997us/step - loss: 0.2227 - acc: 0.9168 - val_loss: 0.3455 - val_acc: 0.8590\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.1934 - acc: 0.9304 - val_loss: 0.4071 - val_acc: 0.8376\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.1457 - acc: 0.9479 - val_loss: 0.3957 - val_acc: 0.8552\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.1060 - acc: 0.9636 - val_loss: 0.4532 - val_acc: 0.8196\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.0755 - acc: 0.9762 - val_loss: 0.4479 - val_acc: 0.8534\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.0534 - acc: 0.9836 - val_loss: 0.5488 - val_acc: 0.7944\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.0344 - acc: 0.9899 - val_loss: 0.5609 - val_acc: 0.8286\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])\n",
    "history= model.fit(train_set, train_y, epochs=10, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ジェネレーティブディープラーニング\n",
    "\n",
    "- LSTMを使ったテキスト生成\n",
    "- DeepDreamの実装\n",
    "\n",
    "## LSTMによるテキスト生成\n",
    "\n",
    "ディープラーニングにおいて, シーケンスデータを生成するための普遍的な方法は, 以前のトークンを入力として, シーケンスの次のトークンや次の数個のトークンを入力としてシーケンスの次のトークンや次の数個のトークンを予測するためにネットワークを訓練することである. このネットワークにはRNN, CNNが用いられる. token は一般に単語か文字になる.  （言語モデル)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
